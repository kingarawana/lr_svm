{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "data_path = 'data/linear_svm.pkl'\n",
    "with open(data_path, 'r') as f:\n",
    "    datadict = pickle.load(f)\n",
    "    X = datadict['X']\n",
    "    y = datadict['y']\n",
    "\n",
    "W = np.random.randn(10, 3073) * 0.0001 \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 5.070261 analytic: 5.070261, relative error: 1.569297e-11\n",
      "numerical: 7.667799 analytic: 7.695079, relative error: 1.775690e-03\n",
      "numerical: -14.636418 analytic: -14.636418, relative error: 1.051177e-11\n",
      "numerical: -28.566789 analytic: -28.566789, relative error: 5.791873e-12\n",
      "numerical: 2.887680 analytic: 2.887680, relative error: 8.576661e-11\n",
      "numerical: -16.510209 analytic: -16.510209, relative error: 1.501965e-11\n",
      "numerical: -3.969103 analytic: -3.969103, relative error: 1.708214e-10\n",
      "numerical: -0.613207 analytic: -0.613207, relative error: 3.501153e-10\n",
      "numerical: 22.120150 analytic: 22.098912, relative error: 4.803047e-04\n",
      "numerical: -21.299394 analytic: -21.299394, relative error: 6.462537e-12\n"
     ]
    }
   ],
   "source": [
    "from files.linear_svm import *\n",
    "from files.gradient_check import grad_check\n",
    "\n",
    "loss, grad = svm_loss_naive(W, X, y, 0)\n",
    "f = lambda w: svm_loss_naive(w, X, y, 0.0)[0]\n",
    "\n",
    "grad_numerical = grad_check(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive loss: 8.887717e+00 computed in 0.017818s\n",
      "0.0\n",
      "0.0\n",
      "Vectorized loss: 1.606408e+00 computed in 0.002470s\n",
      "difference: 7.281309. Vectorized version is 7.213707x faster\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "loss_naive, grad_naive = svm_loss_naive(W, X, y, 0.00001)\n",
    "stop = time.time()\n",
    "naive_time = stop - start\n",
    "\n",
    "print 'Naive loss: %e computed in %fs' % (loss_naive, stop - start)\n",
    "\n",
    "start = time.time()\n",
    "loss_vectorized, _ = svm_loss_vectorized(W, X, y, 0.00001)\n",
    "stop = time.time()\n",
    "vectorized_time = stop - start\n",
    "\n",
    "print 'Vectorized loss: %e computed in %fs' % (loss_vectorized, stop - start)\n",
    "\n",
    "# The loss difference should be 0, but your vectorized implementation should be much faster.\n",
    "print 'difference: %f. Vectorized version is %fx faster' % (loss_naive - loss_vectorized, naive_time/vectorized_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
